# -*- coding: utf-8 -*-
"""book-rec_model-build.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B6En-OhahXsKhcjCJXwp5AuBf69hZxsx
"""

import pandas as pd
import numpy as np

data = pd.read_csv('oau_books_cleaned2.csv')

data.head(20)

data.tail(100)

data.info()

"""## DATA ANALYSIS"""

import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid")

data['Author'].nunique(), data['Title'].nunique(), data['Publisher'].nunique()

data['Author'].value_counts().head(10)
top_authors = data['Author'].value_counts().head(10)

plt.figure(figsize=(10, 6))
sns.barplot(y=top_authors.index, x=top_authors.values, palette="crest")
plt.title("Top 10 Most Frequent Authors")
plt.xlabel("Number of Books")
plt.ylabel("Author")
plt.tight_layout()
plt.show()

data['Publisher'].value_counts().head(10)
top_publishers = data['Publisher'].value_counts().head(10)

plt.figure(figsize=(10, 6))
sns.barplot(y=top_publishers.index, x=top_publishers.values, palette="flare")
plt.title("Top 10 Publishers")
plt.xlabel("Number of Books")
plt.ylabel("Publisher")
plt.tight_layout()
plt.show()

data['Year'].value_counts().sort_index().tail(20)

data['Pages'].describe()
plt.figure(figsize=(10, 6))
sns.histplot(data[data['Pages'] > 0]['Pages'], bins=40, kde=True, color='mediumseagreen')
plt.title("Distribution of Book Pages")
plt.xlabel("Number of Pages")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

data['Format'].value_counts()

"""## dropping irrelevaces"""

selected_cols = [
    'Title', 'Author', 'Publisher', 'Year', 'Pages',
    'Format', 'Literary Form', 'Material Type', 'Image URL', 'Link'
]
data = data[selected_cols]

data.info()

data.head()

"""## model build"""

pip install sentence-transformers

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import NearestNeighbors

import os
from transformers import AutoTokenizer, AutoModel
os.environ["USE_TF"] = "0"  # Disable TensorFlow
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")

data['text_features'] = data['Title'] + ' ' + data['Author'] + ' ' + data['Publisher'] + ' ' + data['Format'] + ' ' + data['Literary Form']
scaler = MinMaxScaler()
data['Pages_scaled'] = scaler.fit_transform(data[['Pages']])

from sentence_transformers import SentenceTransformer

tfidf_vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf_vectorizer.fit_transform(data['text_features'])

model = SentenceTransformer('all-MiniLM-L6-v2')
semantic_embeddings = model.encode(data['text_features'], show_progress_bar=True)

hybrid_features = np.hstack((
    tfidf_matrix.toarray(),
    data[['Pages_scaled']].values,
    semantic_embeddings
))

knn = NearestNeighbors(n_neighbors=6, metric='cosine')
knn.fit(hybrid_features)





def recommend_books(title, top_n=5):
    idx = data[data['Title'].str.lower() == title.lower()].index
    if len(idx) == 0:
        return "‚ùå Book not found."
    idx = idx[0]
    distances, indices = knn.kneighbors([hybrid_features[idx]], n_neighbors=top_n + 1)

    print(f"\nüìò Recommendations for: {data.loc[idx, 'Title']}\n")
    for i, rec_idx in enumerate(indices[0][1:]):
        print(f"{i+1}. {data.loc[rec_idx, 'Title']} by {data.loc[rec_idx, 'Author']} ({int(data.loc[rec_idx, 'Pages'])} pages)")

def recommend_from_text_query(query, top_n=5):
    query_tfidf = tfidf_vectorizer.transform([query])
    query_embed = model.encode([query])
    query_pages = np.array([[0]])  # Assume 0 pages for query

    query_features = np.hstack((
        query_tfidf.toarray(),
        scaler.transform(query_pages),
        query_embed
    ))

    distances, indices = knn.kneighbors(query_features, n_neighbors=top_n)
    print(f"\nüîç Recommendations for query: '{query}'\n")
    for i, idx in enumerate(indices[0]):
        print(f"{i+1}. {data.loc[idx, 'Title']} by {data.loc[idx, 'Author']} ({int(data.loc[idx, 'Pages'])} pages)")

recommend_books("computer", top_n=5)
recommend_from_text_query("python", top_n=5)

from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
model.save('saved_book-recommender_model')
loaded_model = SentenceTransformer('saved_book-recommender_model')

model.save('book-recommender_model')
import shutil
shutil.make_archive('book-recommender_model', 'zip', 'book-recommender_model')

from google.colab import files
files.download('book-recommender_model.zip')

